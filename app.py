import streamlit as st
import json
import re
import time
import random
from typing import Dict, List

# --- LangChain æ–°å¢å¼•å…¥ ---
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain.memory import ConversationBufferWindowMemory
from pydantic import BaseModel, Field

# --- ä½ çš„è‡ªå®šä¹‰æ¨¡å— ---
import case_config as config
import ui_components  # å¯¼å…¥ UI ç»„ä»¶åº“

# ====================
# 1. åŸºç¡€é…ç½®
# ====================
st.set_page_config(page_title="å…­æ€’æ±‰ï¼šæ·±åº¦ä¸ªä½“æ¨¡æ‹Ÿ", layout="wide")

# åŠ è½½æ¥è‡ª ui_components çš„ CSS æ ·å¼
st.markdown(ui_components.CUSTOM_CSS, unsafe_allow_html=True)

if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "llm_provider" not in st.session_state:
    st.session_state.llm_provider = "DeepSeek"
if "model_name" not in st.session_state:
    st.session_state.model_name = "deepseek-chat"
if "api_base" not in st.session_state:
    st.session_state.api_base = ""

# --- ä¾§è¾¹æ æ§åˆ¶å° (ä¿æŒä½ åŸæœ‰çš„é€»è¾‘ä¸å˜) ---
with st.sidebar:
    st.header("ğŸ§  ä¸Šå¸è§†è§’æ§åˆ¶å°")

    # æ¨¡å‹æä¾›å•†é€‰æ‹©
    st.session_state.llm_provider = st.selectbox(
        "é€‰æ‹©å¤§æ¨¡å‹æä¾›å•†",
        options=["DeepSeek", "OpenAI", "è‡ªå®šä¹‰(OpenAIå…¼å®¹)"],
        index=["DeepSeek", "OpenAI", "è‡ªå®šä¹‰(OpenAIå…¼å®¹)"].index(
            st.session_state.llm_provider
        )
        if st.session_state.llm_provider in ["DeepSeek", "OpenAI", "è‡ªå®šä¹‰(OpenAIå…¼å®¹)"]
        else 0,
    )

    # æ ¹æ®æä¾›å•†è®¾ç½®é»˜è®¤æ¨¡å‹åä¸æç¤ºæ–‡æ¡ˆ
    if st.session_state.llm_provider == "DeepSeek":
        key_label = "DeepSeek API Key"
        default_model = "deepseek-chat"
    elif st.session_state.llm_provider == "OpenAI":
        key_label = "OpenAI API Key"
        default_model = "gpt-4o-mini"
    else:  # è‡ªå®šä¹‰ OpenAI å…¼å®¹
        key_label = "API Key"
        default_model = st.session_state.model_name or "your-model-name"

    st.session_state.api_key = st.text_input(
        key_label, type="password", value=st.session_state.api_key
    )

    st.session_state.model_name = st.text_input(
        "æ¨¡å‹åç§°",
        value=st.session_state.model_name or default_model,
        help="ä¾‹å¦‚ï¼šDeepSeek ä½¿ç”¨ deepseek-chatï¼›OpenAI ä½¿ç”¨ gpt-4o / gpt-4o-mini ç­‰",
    )

    # åªæœ‰åœ¨â€œè‡ªå®šä¹‰(OpenAIå…¼å®¹)â€æ¨¡å¼ä¸‹æ‰éœ€è¦å¡«å†™ base_url
    if st.session_state.llm_provider == "è‡ªå®šä¹‰(OpenAIå…¼å®¹)":
        st.session_state.api_base = st.text_input(
            "è‡ªå®šä¹‰ API Base URL",
            value=st.session_state.api_base or "",
            placeholder="ä¾‹å¦‚ï¼šhttps://dashscope.aliyuncs.com/compatible-mode/v1",
        )

    if not st.session_state.api_key: st.warning("è¯·è¾“å…¥ Key"); st.stop()
    
    st.divider()
    auto_rounds = st.number_input("è‡ªåŠ¨è¿è¡Œè½®æ•°", 1, 15, 1)
    run_btn = st.button("â–¶ï¸ å¼€å§‹æ·±åº¦æ¨¡æ‹Ÿ", type="primary")
    
    st.divider()
    if st.button("ğŸ—‘ï¸ é‡ç½®ä¸–ç•Œ"): st.session_state.clear(); st.rerun()

# åˆå§‹åŒ– LLM (ä¿æŒä¸å˜)
if st.session_state.llm_provider == "DeepSeek":
    llm = ChatOpenAI(
        model=st.session_state.model_name or "deepseek-chat",
        openai_api_key=st.session_state.api_key,
        openai_api_base="https://api.deepseek.com",
        temperature=0.9,
    )
elif st.session_state.llm_provider == "OpenAI":
    llm = ChatOpenAI(
        model=st.session_state.model_name or "gpt-4o-mini",
        openai_api_key=st.session_state.api_key,
        temperature=0.9,
    )
else:
    llm = ChatOpenAI(
        model=st.session_state.model_name,
        openai_api_key=st.session_state.api_key,
        openai_api_base=st.session_state.api_base or None,
        temperature=0.9,
    )

# ====================
# 2. çŠ¶æ€åˆå§‹åŒ– (å‡çº§ç‰ˆï¼šç‹¬ç«‹è®°å¿†)
# ====================
if "history" not in st.session_state:
    # è¿™æ˜¯å…¨å±€å…¬å¼€çš„å‰§æœ¬ï¼Œç”¨äºUIæ˜¾ç¤º
    st.session_state.history = [{"role": "Foreman", "content": "ç¬¬ä¸€è½®æŠ•ç¥¨ 5:1ã€‚Davisï¼Œè¯·é™ˆè¿°ä½ çš„ç†ç”±ã€‚"}]

if "agents_memories" not in st.session_state:
    st.session_state.agents_memories = {}
    
    for name in config.AGENTS:
        # ä¸åŒäººå¯ä»¥æœ‰ä¸åŒçš„è®°å¿†åŠ› (kå€¼)
        # ä¾‹å¦‚ï¼šè€å¹´äºº(McCardle)è®°å¿†çŸ­ï¼Œå»ºç­‘å¸ˆ(Davis)è®°å¿†é•¿
        k_value = 5 if config.AGENTS[name]['age'] > 65 else 10
        
        memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            k=k_value,
            return_messages=True
        )
        
        # é¢„åŸ‹åˆå§‹èƒŒæ™¯
        memory.chat_memory.add_user_message("System: æ¡ˆä»¶å®¡ç†å¼€å§‹ã€‚è¯·åŸºäºä½ çš„è¯æ®å’Œç›´è§‰è¿›è¡Œè¾©è®ºã€‚")
        st.session_state.agents_memories[name] = memory

    if "agents_state" not in st.session_state:
        st.session_state.agents_state = {}
        for name in config.AGENTS:
            st.session_state.agents_state[name] = {
                "score": config.AGENTS[name]["init_score"],
                "last_speech": "...",
                # â†“â†“â†“ æ³¨æ„è¿™é‡Œï¼Œå¤§æ‹¬å·åé¢å¿…é¡»åŠ é€—å·
                "relationships": {other: 0 for other in config.AGENTS if other != name}, 
                
                # æ³¨æ„ï¼šprivate_memory ç°åœ¨å¯ä»¥ç”± LangChain Memory æ¥ç®¡ä¸€éƒ¨åˆ†ï¼Œ
                # ä½†ä¸ºäº†ä¿ç•™â€œé•¿æœŸæ·±å±‚è®°å¿†â€ï¼Œæˆ‘ä»¬ä¾ç„¶ä¿ç•™è¿™ä¸ªåˆ—è¡¨
                "private_memory": config.AGENTS[name].get("initial_memory", []), 
            }

if "current_speaker" not in st.session_state: st.session_state.current_speaker = None


# ====================
# 3. LangChain ç»“æ„å®šä¹‰ (å‡çº§ç‰ˆ)
# ====================

class JurorAction(BaseModel):
    internal_thought: str = Field(description="å†…å¿ƒç‹¬ç™½ï¼šåˆ†æè¯æ®ï¼Œè¯„ä»·ä¸Šä¸€ä½å‘è¨€è€…ï¼Œä¸è¦è¯´å®¢å¥—è¯ã€‚")
    
    # æ–°å¢ï¼šå…¬å¼€ç«‹åœºï¼Œç”¨äºUIæ˜¾ç¤ºæ ‡ç­¾ï¼Œè€Œä¸æ˜¯æ˜¾ç¤ºæ•°å­—
    public_stance: str = Field(description="å…¬å¼€è¡¨è¾¾çš„ç«‹åœºï¼Œåªèƒ½æ˜¯ä»¥ä¸‹ä¸‰ä¸ªä¹‹ä¸€ï¼š['æ— ç½ª', 'çŠ¹è±«', 'æœ‰ç½ª']")
    
    # å…³é”®ä¿®æ”¹ï¼šæ˜ç¡®è¦æ±‚å‘è¨€ä¸­ä¸è¦å¸¦æ•°å­—
    speech: str = Field(description="å…¬å¼€å‘è¨€ï¼šç”¨è‡ªç„¶çš„å£è¯­è¡¨è¾¾ï¼Œä¸¥ç¦åœ¨è¯è¯­ä¸­ç›´æ¥è¯´å‡ºåˆ†æ•°æ•°å€¼ï¼æ¯”å¦‚ä¸è¦è¯´'æˆ‘æ‰“80åˆ†'ï¼Œè¦è¯´'æˆ‘éå¸¸ç¡®ä¿¡ä»–æœ‰ç½ª'ã€‚")
    
    relationship_update: Dict[str, int] = Field(description="å¥½æ„Ÿåº¦å˜åŒ–ï¼š{'äººå': -5åˆ°5ä¹‹é—´çš„æ•´æ•°}")
    
    # è¿™ä¸ªåˆ†æ•°ä¾ç„¶ä¿ç•™ï¼Œä½œä¸ºåº•å±‚é©±åŠ¨ï¼Œä½†å¯¹å…¶ä»–Agentä¸å¯è§
    new_score: int = Field(description="å†…å¿ƒçœŸå®çš„å®šç½ªç¡®ä¿¡åº¦ (0-100)ã€‚0=ç¡®ä¿¡æ— ç½ªï¼Œ100=ç¡®ä¿¡æœ‰ç½ªã€‚")

juror_parser = PydanticOutputParser(pydantic_object=JurorAction)

agent_template_str = """
ä½ ç°åœ¨æ˜¯: {name} (å¹´é¾„: {age}, èŒä¸š: {occupation})ã€‚

ã€äººç‰©è®¾å®šã€‘:
{backstory}
ã€æ ¸å¿ƒä»·å€¼è§‚ã€‘: {core_values}

ã€å½“å‰çŠ¶æ€ã€‘:
ä½ çš„å†…å¿ƒå®šç½ªåˆ†æ•°: {current_score}/100ã€‚
å±€åŠ¿æ„ŸçŸ¥(ä¸Šä¸€ä½å‘è¨€è€…): {last_speaker_name} (å¥½æ„Ÿåº¦: {last_speaker_rel})

ã€ä½ çš„ä¸“å±è®°å¿†æµã€‘:
ä»¥ä¸‹æ˜¯ä½ è„‘æµ·ä¸­å…³äºæœ€è¿‘å¯¹è¯çš„è®°å¿†ï¼ˆHumanä»£è¡¨å…¶ä»–äººï¼ŒAIä»£è¡¨ä½ è‡ªå·±ï¼‰ï¼š
{chat_history}

ã€æ€è€ƒä»»åŠ¡ã€‘:
1. å›é¡¾ã€è®°å¿†æµã€‘ï¼Œæ³¨æ„ä½ ä¹‹å‰çš„ç«‹åœºå’Œä½ å¯¹ä»–äººçš„çœ‹æ³•ã€‚
2. ç»“åˆä¸Šä¸€å¥å‘è¨€è¿›è¡Œå›åº”ã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘:
(ä¿æŒåŸæœ‰ JSON æ ¼å¼è¦æ±‚)
{format_instructions}
"""

agent_prompt_template = PromptTemplate(
    template=agent_template_str,
    input_variables=[
        "name", "age", "occupation", "backstory", "core_values", 
        "current_score", "last_speaker_name", "last_speaker_rel", 
        "chat_history" # <--- å˜é‡åå˜äº†
    ],
    partial_variables={"format_instructions": juror_parser.get_format_instructions()}
)

agent_prompt_template = PromptTemplate(
    template=agent_template_str,
    input_variables=[
        "name", "age", "occupation", "backstory", "core_values", 
        "speaking_style", "current_score", "private_memory", 
        "last_speaker_name", "last_speaker_rel", "case_background", "history_text"
    ],
    partial_variables={"format_instructions": juror_parser.get_format_instructions()}
)


# ====================
# 4. æ ¸å¿ƒé€»è¾‘ (æ•´åˆäº†ä½ çš„é€»è¾‘å’ŒLangChain)
# ====================

def run_one_turn():
    # --- A. é€‰äººé€»è¾‘ (ä¿æŒä¸å˜) ---
    visible_history = st.session_state.history[-10:]
    history_text_for_supervisor = "\n".join([f"{m['role']}: {m['content']}" for m in visible_history])
    
    recent_speakers = [m["role"] for m in st.session_state.history[-3:]]
    candidates = [n for n in config.AGENTS if n not in recent_speakers]
    if not candidates:
        last = recent_speakers[-1] if recent_speakers else ""
        candidates = [n for n in config.AGENTS if n != last]

    try:
        # (Supervisor ä»£ç çœç•¥ï¼Œä¿æŒåŸæ ·) ...
        # å‡è®¾è¿™é‡Œé€‰å‡ºäº† next_speaker
        next_speaker = random.choice(candidates) # æˆ–è€…ä½ åŸæ¥çš„é€»è¾‘
        st.session_state.current_speaker = next_speaker

        # --- B. æ·±åº¦æ¨¡æ‹Ÿé€»è¾‘ (Memory æ¥å…¥) ---
        state = st.session_state.agents_state[next_speaker]
        conf = config.AGENTS[next_speaker]
        
        # 1. è·å–è¯¥ Agent çš„ç‹¬ç«‹è®°å¿†å¯¹è±¡
        agent_memory = st.session_state.agents_memories[next_speaker]
        
        # 2. ä» Memory ä¸­åŠ è½½å†å²è®°å½• (æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²)
        # load_memory_variables è¿”å›çš„æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« chat_history
        memory_vars = agent_memory.load_memory_variables({})
        chat_history_str = str(memory_vars.get("chat_history", ""))

        last_msg = st.session_state.history[-1]
        last_speaker = last_msg["role"]
        rel_score = state["relationships"].get(last_speaker, 0)
        current_score = state["score"]

        # 3. æ„é€  Prompt
        final_prompt = agent_prompt_template.format(
            name=next_speaker,
            age=conf['age'],
            occupation=conf['occupation'],
            backstory=conf['backstory'],
            core_values=conf['core_values'],
            current_score=current_score,
            last_speaker_name=last_speaker,
            last_speaker_rel=rel_score,
            chat_history=chat_history_str  # <--- ä¼ å…¥ç‹¬ç«‹è®°å¿†å­—ç¬¦ä¸²
        )

        response = llm.invoke([HumanMessage(content=final_prompt)])
        parsed_action = juror_parser.parse(response.content)
        data = parsed_action.dict()

        if data:
            # --- C. å¤„ç†æƒ¯æ€§å’ŒçŠ¶æ€ (ä¿æŒä¸å˜) ---
            target_score = int(data.get("new_score", current_score))
            delta = target_score - current_score
            max_change = 15
            if delta > max_change: delta = max_change
            elif delta < -max_change: delta = -max_change
            real_new_score = max(0, min(100, current_score + delta))
            
            state["score"] = real_new_score
            state["last_speech"] = data["speech"]
            
            # --- ğŸ”¥ D. å…³é”®ï¼šå¹¿æ’­æ›´æ–°æ‰€æœ‰äººçš„è®°å¿† ---
            speech_content = data["speech"]
            internal_thought = data["internal_thought"]

            for agent_name, mem in st.session_state.agents_memories.items():
                if agent_name == next_speaker:
                    # å¯¹äºã€æˆ‘è‡ªå·±ã€‘ï¼š
                    # æˆ‘è¦æŠŠâ€œå†…å¿ƒç‹¬ç™½â€+â€œå…¬å¼€è®²è¯â€éƒ½å­˜è¿›å»ï¼Œå½¢æˆ Chain of Thought
                    # è¿™æ ·æˆ‘ä¸‹æ¬¡å°±èƒ½è®°å¾—æˆ‘ä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´äº†
                    combined_input = f"(å†…å¿ƒç‹¬ç™½: {internal_thought}) -> æˆ‘è¯´: {speech_content}"
                    mem.chat_memory.add_ai_message(combined_input)
                else:
                    # å¯¹äºã€å…¶ä»–äººã€‘ï¼š
                    # ä»–ä»¬åªèƒ½å¬åˆ°æˆ‘çš„â€œå…¬å¼€è®²è¯â€
                    mem.chat_memory.add_user_message(f"{next_speaker} è¯´: {speech_content}")

            # å¤„ç†å…³ç³»æ›´æ–° (ä¿æŒä¸å˜)
            for target, change in data["relationship_update"].items():
                if target in state["relationships"]:
                    state["relationships"][target] += int(change)

            # å†™å…¥å…¨å±€ UI å†å²
            st.session_state.history.append({
                "role": next_speaker, 
                "content": speech_content,
                "stance": data["public_stance"]
            })
            return True

        return False

    except Exception as e:
        st.error(f"Error: {e}")
        return False



# ====================
# 5. ç•Œé¢æ¸²æŸ“ (ä¿æŒä¸å˜)
# ====================
st.title("âš–ï¸ åäºŒæ€’æ±‰ï¼šæ·±åº¦ä¸ªä½“æ¨¡æ‹Ÿ")

st.subheader("ğŸ›ï¸ é™ªå®¡å›¢å¸­ä½ (ä¸Šå¸è§†è§’)")
cols = st.columns(3)

# æ¸²æŸ“å¡ç‰‡
for i, name in enumerate(config.AGENTS.keys()):
    state = st.session_state.agents_state[name]
    conf = config.AGENTS[name]
    is_active = (name == st.session_state.current_speaker)

    with cols[i % 3]:
        html_code = ui_components.generate_card_html(name, conf, state, is_active)
        st.markdown(html_code, unsafe_allow_html=True)

# --- è‡ªåŠ¨è¿è¡Œå¾ªç¯ ---
if run_btn:
    bar = st.progress(0)
    for i in range(auto_rounds):
        success = run_one_turn()
        bar.progress((i+1)/auto_rounds)
        if not success: break
        time.sleep(1) 
    st.rerun()

# --- å†å²è®°å½• ---
# --- å†å²è®°å½• ---
st.divider()
st.subheader("ğŸ“œ æ¡ˆä»¶è®°å½•")
for msg in reversed(st.session_state.history):
    role = msg['role']
    avatar = config.AGENTS.get(role, {}).get("avatar", "ğŸ¤–")
    
    if role == "System":
        st.info(msg['content'])
    else:
        with st.chat_message(role, avatar=avatar):
            # è·å–ç«‹åœºæ ‡ç­¾ï¼Œå¦‚æœæ²¡æœ‰ï¼ˆæ—§è®°å½•ï¼‰åˆ™ä¸æ˜¾ç¤º
            stance = msg.get("stance", "")
            
            # å®šä¹‰æ ‡ç­¾é¢œè‰²
            badge_color = "gray"
            if stance == "æœ‰ç½ª": badge_color = "red"
            elif stance == "æ— ç½ª": badge_color = "green"
            elif stance == "çŠ¹è±«": badge_color = "orange"
            
            # æ˜¾ç¤ºå†…å®¹ï¼šå¦‚æœå­˜åœ¨ç«‹åœºï¼Œå…ˆæ˜¾ç¤ºç«‹åœºå¾½ç« 
            if stance:
                st.markdown(f":{badge_color}[ã€{stance}ã€‘] {msg['content']}")
            else:
                st.write(msg['content'])
            
            # (å¯é€‰) å¦‚æœä½ æ˜¯è°ƒè¯•æ¨¡å¼ï¼Œå¯ä»¥æŠŠè¿™ä¸€è¡Œå–æ¶ˆæ³¨é‡Šçœ‹çœ‹çœŸå®åˆ†æ•°å˜åŒ–
            # st.caption(f"Debug Score: {msg.get('score_debug', 'N/A')}")
